# -*- coding: utf-8 -*-
"""Data_Mining_Capstone_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_eym5oYk5Ot0Iwzqe64KedeB8YeA67Fd
"""

# Install yfinance package
!pip install yfinance

import yfinance as yf
import pandas as pd
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# Fetch S&P 500 tickers
table = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')
sp500_tickers = table[0]['Symbol'].tolist()
sp500_tickers = [ticker.replace('.', '-') for ticker in sp500_tickers]

# Initialize an empty list to store the data
data = []

# Loop through each ticker symbol
for ticker in sp500_tickers:
    # Fetch the ticker data
    stock = yf.Ticker(ticker)

    # Get the info and extract 'previousClose' and 'volume'
    info = stock.info
    previous_close = info.get('previousClose', None)
    volume = info.get('volume', None)

    # Append a dictionary to the data list
    data.append({
        'Ticker': ticker,
        'PreviousClose': previous_close,
        'Volume': volume
    })

# Convert the list of dictionaries into a DataFrame
df_stocks = pd.DataFrame(data)

df_stocks.head()

df_stocks.info()

df_volume_greater_than_mil = df_stocks[df_stocks['Volume'] > 1000000]

df_volume_greater_than_mil.info()

# Define the Ichimoku Cloud calculation function
def calculate_ichimoku_cloud(df):
    tenkan_period = 9
    kijun_period = 26
    senkou_span_b_period = 52

    df['conversion_line'] = (df['High'].rolling(window=tenkan_period).max() + df['Low'].rolling(window=tenkan_period).min()) / 2
    df['base_line'] = (df['High'].rolling(window=kijun_period).max() + df['Low'].rolling(window=kijun_period).min()) / 2
    df['senkou_span_a'] = ((df['conversion_line'] + df['base_line']) / 2).shift(kijun_period)
    df['senkou_span_b'] = ((df['High'].rolling(window=senkou_span_b_period).max() + df['Low'].rolling(window=senkou_span_b_period).min()) / 2).shift(kijun_period)

    return df

# Define the function to check if the last price is above the Ichimoku Cloud
def check_above_cloud(last_price, span_a, span_b):
    if last_price >= span_a and last_price >= span_b:
        return "ABOVE CLOUD"
    else:
        return "NOT ABOVE CLOUD"

# Fetch historical data for each stock and apply the Ichimoku Cloud calculation
for ticker in df_volume_greater_than_mil['Ticker']:
    stock_data = yf.download(ticker, period="max")
    stock_data_ichimoku = calculate_ichimoku_cloud(stock_data)

    # Assuming 'last_price' is the last 'Close' price from the historical data
    last_price = stock_data['Close'].iloc[-1]
    span_a = stock_data['senkou_span_a'].iloc[-1]
    span_b = stock_data['senkou_span_b'].iloc[-1]

    # Check if the last price is above the Ichimoku Cloud and assign the result to the 'CloudStatus' column
    cloud_status = check_above_cloud(last_price, span_a, span_b)

    # Find the index of the current ticker in 'df_filtered'
    index = df_volume_greater_than_mil[df_volume_greater_than_mil['Ticker'] == ticker].index[0]

    # Assign the cloud status to the new column 'CloudStatus' for the corresponding row in 'df_filtered'
    df_volume_greater_than_mil.at[index, 'CloudStatus'] = cloud_status

df_volume_greater_than_mil.head()

# Define the Awesome Oscillator calculation function
def calculate_awesome_oscillator(df, short_period=5, long_period=34):
    # Calculate the midpoint ((High + Low) / 2) of each bar
    df['Midpoint'] = (df['High'] + df['Low']) / 2

    # Calculate the short and long period SMAs of the midpoints
    df['SMA_Short'] = df['Midpoint'].rolling(window=short_period).mean()
    df['SMA_Long'] = df['Midpoint'].rolling(window=long_period).mean()

    # Calculate the Awesome Oscillator
    df['AO'] = df['SMA_Short'] - df['SMA_Long']

    return df

# Assuming df_filtered is your DataFrame with the filtered tickers
# Initialize a list to store the Awesome Oscillator values
ao_values = []

# Fetch historical data for each stock and calculate the Awesome Oscillator
for ticker in df_volume_greater_than_mil['Ticker']:
    # Download historical stock data
    stock_data = yf.download(ticker, period='max')

    # Calculate Awesome Oscillator
    stock_data_with_ao = calculate_awesome_oscillator(stock_data)

    # Get the last Awesome Oscillator value
    ao_last_value = stock_data_with_ao['AO'].iloc[-1]

    # Append to the list of AO values
    ao_values.append(ao_last_value)

# Add the AO values as a new column to df_filtered
df_volume_greater_than_mil['Awesome_Oscillator'] = ao_values

df_volume_greater_than_mil.head()

# Define the interpretation functions
def interpret_ao(ao_value):
    return "BULLISH" if ao_value >= 0 else "BEARISH"

def interpret_ao_movement(current_ao, previous_ao):
    if current_ao >= 0 and previous_ao < current_ao:
        return "BULLISH_INCREASING"
    elif current_ao >= 0 and previous_ao > current_ao:
        return "BULLISH_DECREASING"
    elif current_ao < 0 and previous_ao < current_ao:
        return "BEARISH_INCREASING"
    elif current_ao < 0 and previous_ao > current_ao:
        return "BEARISH_DECREASING"
    return "STABLE"  # If current and previous AO values are the same

# Initialize lists to store the interpretation results
ao_interpretation_list = []
ao_movement_list = []

# Fetch historical data for each stock and calculate indicators
for ticker in df_volume_greater_than_mil['Ticker']:
    # Download historical stock data
    stock_data = yf.download(ticker, period='max')

    # Calculate Awesome Oscillator
    stock_data_with_ao = calculate_awesome_oscillator(stock_data)

    # Get the last two Awesome Oscillator values
    if len(stock_data_with_ao['AO']) >= 2:
        current_ao = stock_data_with_ao['AO'].iloc[-1]
        previous_ao = stock_data_with_ao['AO'].iloc[-2]
    else:
        # Handle cases where there are not enough data points
        current_ao = previous_ao = None  # or use np.nan to denote missing values

    # Interpret the AO value and movement
    ao_interpretation = interpret_ao(current_ao) if current_ao is not None else None
    ao_movement = interpret_ao_movement(current_ao, previous_ao) if None not in (current_ao, previous_ao) else None

    # Append the interpretations to the lists
    ao_interpretation_list.append(ao_interpretation)
    ao_movement_list.append(ao_movement)

# Add the interpretation and movement columns to df_filtered
df_volume_greater_than_mil['AO_Interpretation'] = ao_interpretation_list
df_volume_greater_than_mil['AO_Movement'] = ao_movement_list

df_volume_greater_than_mil.head()

# Define the VWAP calculation function
def calculate_vwap(df):
    df['VWAP'] = (df['Close'] * df['Volume']).cumsum() / df['Volume'].cumsum()
    return df

# Initialize a list to store the VWAP values
vwap_values = []

# Fetch historical data for each stock and calculate VWAP
for ticker in df_volume_greater_than_mil['Ticker']:
    # Download historical stock data
    stock_data = yf.download(ticker, period='max')

    # Calculate VWAP
    stock_data_with_vwap = calculate_vwap(stock_data)

    # Get the last VWAP value
    vwap_last_value = stock_data_with_vwap['VWAP'].iloc[-1]

    # Append to the list of VWAP values
    vwap_values.append(vwap_last_value)

# Add the VWAP values as a new column to df_filtered
df_volume_greater_than_mil['VWAP'] = vwap_values

df_volume_greater_than_mil.head()

# Define the function to calculate EMA using pandas 'ewm' method
def calculate_ema(series, span):
    return series.ewm(span=span, adjust=False).mean()

# Fetch historical data for each stock and calculate EMAs
for ticker in df_volume_greater_than_mil['Ticker']:
    # Download historical stock data
    stock_data = yf.download(ticker, period='max')

    # Calculate each EMA and its percent difference from the close price
    for window in [20, 36, 50, 95, 200]:
        ema_column_name = f'EMA_{window}'
        stock_data[ema_column_name] = calculate_ema(stock_data['Close'], span=window)
        stock_data[f'{ema_column_name}_Percent'] = ((stock_data['Close'] - stock_data[ema_column_name]) / stock_data['Close'] * 100).round(2)

    # Get the last values of each EMA and its percent difference
    for window in [20, 36, 50, 95, 200]:
        ema_column_name = f'EMA_{window}'
        df_volume_greater_than_mil.loc[df_volume_greater_than_mil['Ticker'] == ticker, ema_column_name] = stock_data[ema_column_name].iloc[-1]
        df_volume_greater_than_mil.loc[df_volume_greater_than_mil['Ticker'] == ticker, f'{ema_column_name}_Percent'] = stock_data[f'{ema_column_name}_Percent'].iloc[-1]

# df_filtered now has the EMA columns and their percent differences

df_volume_greater_than_mil.head()

# Define the function to calculate smoothed RSI
def calculate_rsi(data, periods=14):
    delta = data.diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=periods).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=periods).mean()

    RS = gain / loss
    RSI = 100 - (100 / (1 + RS))

    return RSI

# Define the function to calculate traditional RSI
def calculate_rsi_Trad(data, period=14):
    delta = data.diff(1)
    gain = (delta.where(delta > 0, 0)).fillna(0)
    loss = (-delta.where(delta < 0, 0)).fillna(0)

    average_gain = gain.rolling(window=period).mean()
    average_loss = loss.rolling(window=period).mean()

    rs = average_gain / average_loss
    rsi = 100 - (100 / (1 + rs))

    return rsi

# Fetch historical data for each stock and calculate RSIs
for ticker in df_volume_greater_than_mil['Ticker']:
    # Download historical stock data
    stock_data = yf.download(ticker, period='max')

    # Ensure there is enough data to calculate RSI
    if len(stock_data) > 14:
        # Calculate Smoothed RSI and Traditional RSI
        stock_data['RSI_Smoothed'] = calculate_rsi(stock_data['Close'])
        stock_data['RSI_Trad'] = calculate_rsi_Trad(stock_data['Close'])

        # Get the last values of each RSI
        last_rsi_smoothed = stock_data['RSI_Smoothed'].iloc[-1]
        last_rsi_trad = stock_data['RSI_Trad'].iloc[-1]
    else:
        last_rsi_smoothed = None
        last_rsi_trad = None

    # Assign the last RSI values to the corresponding ticker in df_filtered
    df_volume_greater_than_mil.loc[df_volume_greater_than_mil['Ticker'] == ticker, 'RSI_Smoothed'] = last_rsi_smoothed
    df_volume_greater_than_mil.loc[df_volume_greater_than_mil['Ticker'] == ticker, 'RSI_Trad'] = last_rsi_trad

# df_filtered now has the two new RSI columns

df_volume_greater_than_mil.head()

# Define the cahold function
def cahold(previous_close, latest_price):
    return "BULLISH" if latest_price >= previous_close else "BEARISH"

# Add a new column to df_filtered for the cahold values
cahold_values = []

# Fetch historical data for each stock
for ticker in df_volume_greater_than_mil['Ticker']:
    # Download historical stock data
    stock_data = yf.download(ticker, period='2d')  # Fetch only the last two days

    # Check if we got at least two days of data to compare the latest and previous close prices
    if len(stock_data) >= 2:
        # Get the latest and previous close prices
        latest_price = stock_data['Close'].iloc[-1]
        previous_close = stock_data['Close'].iloc[-2]

        # Calculate the cahold value
        cahold_value = cahold(previous_close, latest_price)
    else:
        # In case there's not enough data, we can't determine the cahold value
        cahold_value = None

    # Append the cahold value to the list
    cahold_values.append(cahold_value)

# Assign the cahold values to the new column in df_filtered
df_volume_greater_than_mil['Cahold_Status'] = cahold_values

df = df_volume_greater_than_mil

df.tail()

# Set the option to display all columns (None means unlimited)
pd.set_option('display.max_columns', None)

# Set the option to display all rows (None means unlimited)
pd.set_option('display.max_rows', None)

# Assuming 'df' is your DataFrame
print(df.head())

# Output the DataFrame to a CSV file
df.to_csv('full_dataframe.csv', index=False)

"""# comprehensive market analysis and trend forecasting"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

# Filter the data for the MMM ticker
mmm_data = df[df['Ticker'] == 'MMM']